---
title: "Workflow Stan"
author: "Steffen Ernst"
date: "2023-05-01"
output: html_document
---

This document outlines how I derived all the model-related graphs from the data and models.

Setup-Chunk.
```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
if (!require("pacman")) install.packages("pacman"); library(pacman)
p_load(tidyverse, janitor, knitr, forcats, bayesplot, RcppParallel,rstan, BayesFactor, bridgesampling, loo, reticulate, jtools, patchwork, brms, emmeans)
#setwd("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit")

knitr::opts_knit$set(root.dir = "C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit")

options(mc.cores = parallel::detectCores())
options(scipen=999)

```

Model data was stored as ndarray
```{python npy dataset in python}
import numpy as np
posterior_samples_dynamic = np.load("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/STAN/local_post_samples_mrw.npy") # posteriors as ndarray
```

import from python to R
```{r transfer from python to R}
posterior_samples_dynamic <- py$posterior_samples_dynamic #import into R environment
#df <- read_csv("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Experiment/Daten/Daten_cleaned/special/df_min.csv")
```

load the whole dataset for all participants.
```{r load dataset}
df <- read_csv("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Experiment/Daten/Daten_cleaned/special/color_discrimination_data.csv")
```

The following function is used to simulate reaction times (rt) and correct(y/n) from the input variables.

```{r wiener-process function}
wiener_process <- function (v=1, a=1, z=0.5, ndt=0.3) {
  # Standard DDM Model Parameters
  # v   = drift rate
  # a   = boundary separation
  # z   = starting point; = 0.5 corresponds to no bias
  # ndt = non-decision time in s
  
  max_iter <- 1e4 # maximum process duration in ms
  dt <- 0.001    # time steps
  sd <- 1        # sd for noise
  sqrt_dt <- sqrt(dt*sd)
  
  # initialize diffusion path for current trial
  path <-  a * z
  # sample diffusion process noise
  noise <- rnorm(max_iter, 0, 1)
  
  # evidence accumulation process
  iter <- 1
  while (path > 0 & path < a & iter < max_iter) {
    path <- path + v*dt + sqrt_dt*noise[iter]
    iter <- iter + 1
  }
  
  # return response time [s] and choice [0, 1]
  return(c(ndt + iter*dt, as.numeric(path > a)))
}
```


This generates parameter development plots for all 3 parameters, v,a,ndt.
Condition has stored sd and mean values for all parameters. Details on structure in chunk 9.
```{r function generate parameter plot}
generate_parameter_plot <- function(data, condition, difficulty) { 
  # Creates a combined plot, 1 plot for ever parameter_type.
  generate_parameter_subplot <- function(data, parameter_type) {
    #chooses column names and title according to chosen parameter_type.
    if (parameter_type == "v") {
      title <- bquote(paste("drift rate (", italic("v"), ")"))
      mean_dynamic <- sym(names(data)[2])
      mean_static <- sym(names(data)[4])
      sd_dynamic <- sym(names(data)[3])
      sd_static <- sym(names(data)[5]) 
    } else if (parameter_type == "a") {
      columns <- c(1, 6:9)
      title <- bquote(paste("Entscheidungsschwelle (", italic("a"), ")"))
      mean_dynamic <- sym(names(data)[6])
      mean_static <- sym(names(data)[8])
      sd_dynamic <- sym(names(data)[7])
      sd_static <- sym(names(data[9]))
    } else if (parameter_type == "ndt") {
      columns <- c(1, 10:13)
      title <- bquote(paste("non-decision-time (", italic(tau), ")"))
      mean_dynamic <- sym(names(data)[10])
      mean_static <- sym(names(data)[12])
      sd_dynamic <- sym(names(data)[11])
      sd_static <- sym(names(data)[13])
    } else {
      stop("Invalid parameter_type. Use 'v', 'a', or 'ndt'.")
    }
    #calculates ymin/ymax of mean + sd
    ymax <- max(data %>%
                  rowwise() %>%
                  mutate(max_expr = pmax(!!mean_dynamic + !!sd_dynamic, !!mean_static + !!sd_static)) %>%
                  pull(max_expr), na.rm = TRUE)
    ymin <- min(data %>% 
                  rowwise() %>% 
                  mutate(min_expr = pmin(!!mean_dynamic - !!sd_dynamic, !!mean_static - !!sd_static)) %>%
                  pull(min_expr), na.rm = TRUE)
    
    #people start in different condition, either speed or accuracy.
    firstcolour <- ifelse(condition[1]==1,"a","b")    #  "#FCF3DC80", "#FFFFFF33")# gray60 = speedcondition
    secondcolour <- ifelse(firstcolour == "a", "b","a") #firstcolour == "#FCF3DC80"#"#FFFFFF33", "#FCF3DC80")
    colours <- hcl.colors(4, palette = "Mint") #colours <- palette.colors(4, "Teal")
    rects1 <-  data.frame(xstart = seq(0.5, 760.5, 8), xend = seq(8.5, 768.5,8), col = as.character(difficulty[seq(1,768,8)])) #colours[ ____ +1]
    rects2 <-  data.frame(xstart = seq(0.5,758.5,48), xend = seq(48.5,768.5,48), col = rep(c(firstcolour, secondcolour), 8))
    if (parameter_type == "v") {
      rects = rects1
    } else {
      rects = rects2
    }
    
    # cols  <-  c(
    #   "firebrick05" = alpha("firebrick", 0.5),  
    #   "868686_with_less_alpha" = alpha("#7f7f7f",.6),
    #   "a" = "#FCF3DC80",  # speedcondition
    #   "b" = "#FFFFFF33",  # accuracycondition
    #   "0" = "#2A5676",
    #   "1" = "#498EA4",
    #   "2" = "#88C3C8",
    #   "3" = "#D2EEEA",
    #   "firebrick" = "firebrick", 
    #   "black" = "black"
    #   )
#generates 1 plot.
p1 <-
  data %>%
  ggplot() +
  geom_rect(data=rects, aes(ymin=ymin, ymax=ymax, xmin=xstart, xmax=xend, fill=col), alpha =0.5) + #background for condition
  geom_line(aes(x = 1:768, y = !!mean_dynamic, color = "firebrick"), linewidth = .5) +
  geom_line(aes(x = 1:768, y = !!mean_static, color = "black"), linewidth = .5) +
  geom_ribbon(aes(x = 1:768, ymin = !!mean_dynamic - !!sd_dynamic, ymax = !!mean_dynamic + !!sd_dynamic, fill = "firebrick05")) + #, alpha = 0.5
  geom_ribbon(aes(x = 1:768, ymin = !!mean_static - !!sd_static, ymax = !!mean_static + !!sd_static, fill = "868686_with_less_alpha")) + #,alpha = 0.5
  scale_x_continuous(breaks =c(breaks = c(1,seq(48, 768, 48))),
                     labels = c(1,seq(48, 768, 48)),
                     expand = c(0.01,0.01)
                     ) +
  scale_color_manual(
    values = c(
      "firebrick" = "firebrick", 
      "black" = "black"
    ),
    limits = c(
      "firebrick", 
      "black"
    ),
    labels = c(
      "Mittelw. dynamisches DDM",
      "Mittelw. stationäres DDM"
    ),
    name = "",
    drop = T
    ) +
  scale_fill_manual(
    values = c(
      "firebrick05" = alpha("firebrick", 0.5),  
      "868686_with_less_alpha" = alpha("#7f7f7f",.6),
      "a" = "#FCF3DC80",  # speedcondition
      "b" = "white",  # accuracycondition
     "0" = "#D2EEEA",
     "1" = "#88C3C8",
     "2" = "#498EA4",
     "3" = "#2A5676"
    ),
    breaks = c(
      "firebrick05",  
      "868686_with_less_alpha",
     "0",
     "1",
     "2",
     "3",
     "a",  # speedcondition
     "b"
    ),
    limits = c(
          "firebrick05",  
      "868686_with_less_alpha",
     "0",
     "1",
     "2",
     "3",
     "a",  # speedcondition
     "b"
    ),
    labels = c(
     # "Mittelw.dynamisches DDM", 
      "SD dynamisches DDM", 
      #"fast-dm Schätzung", 
      "SD statisches DDM", # Parameter a doesn't have an SD.  ifelse(parameter_type=="a",element_blank(),
      "Schwierigkeit 1",
      "Schwierigkeit 2",
      "Schwierigkeit 3",
      "Schwierigkeit 4",
      "Geschwindigkeits- \n bedingung",
      ""
    ),
    name = "",
    drop = T
  )  +
  guides(
    color = guide_legend(order = 1, nrow = 2),
    fill = guide_legend(order = 2, nrow = 2)
                    #    override.aes = list(color = c("steelblue", "firebrick")))

  )+
  labs(
      title = title,
      x = element_blank(),
      y = "Parameter- \nwert",
  ) +
  ylim(ymin, ymax) +  
 theme_apa(remove.y.gridlines = F) + 
           #remove.x.gridlines = F) +
  theme(
    legend.title = element_text( size=5), 
    legend.text=element_text(size=8),
    legend.position = ifelse(parameter_type=="ndt", "bottom" ,"none"), # bottom left
    legend.justification = ifelse(parameter_type=="ndt", c(0,0) ,"none"), # bottom left
    legend.margin=margin(0,0,0,0),
    legend.box.margin=margin(0,0,0,0),
    legend.box.spacing = unit(0, "pt"),
    plot.margin=unit(c(0,0,0,0), "mm"),
    plot.title = element_text(size=11,
                              margin = margin(5,0,0,0, "mm")),
    axis.title.y=element_text(angle=0, vjust=.5, hjust = 0),
    axis.title.x=element_text(angle=0, 
                              size=11),
    axis.text = element_text(size=11)
    
    #,
    # panel.background = element_blank(),
#    panel.grid.major = element_line(colour="#ececec", linewidth = .2)
  )
  #parameter_comparison <- p1 / p2 # + plot_layout(widths = c(2, 1))
  #return(p1)
  }
  
  #now the subplot function is used on every parameter
  p1 <-  generate_parameter_subplot(data, "v")
  p2 <-  generate_parameter_subplot(data, "a")
  p3 <-  generate_parameter_subplot(data, "ndt") + labs(x="Trialzahl")
  
  #and combined into one single plot.
  parameter_comparison <-  p1/p2/p3#/plot_spacer()/p2/plot_spacer()/p3 + plot_layout(heights = c(10 ,-2 , 10 ,-2 ,10))
  #return(parameter_comparison)
  return(parameter_comparison)
}
generate_parameter_plot(data,condition, difficulty)
ggsave("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/parameter_comparison/parametercomparison_TEST_M1.png" ,  width = 7500, height = 5000, units = "px", dpi = 600)
```

```{r}
generate_comparison_plot_rt <-function(data) {
ggplot(data = data, aes(x = factor(difficulty), y = median_response_time, color = Berechnung)) +
  geom_point(size = 3, position = position_dodge(width = 0.6)) +
  geom_errorbar(aes(ymin = data$lower_ci_rt, ymax = data$upper_ci_rt), width = 0.2, position = position_dodge(width = 0.6)) +
  geom_line(aes(group = Berechnung), position = position_dodge(width = 0.6), linewidth = .5) +
  labs(x = "Schwierigkeit", y = "Reaktionszeit") +
  ggtitle("simulierte und echte Reaktionszeit") +
  scale_color_manual(
    labels = c('emp. Reaktionszeit', 'dynamisches DDM', 'statisches DDM'),  # Optionally, specify custom labels
    breaks = c('Real Data', 'BayesFlow', 'STAN'),  # TODO check whether they are in correct order
    values = c('Real Data' = 'grey', 'BayesFlow' = 'red', 'STAN' = 'steelblue')  # Optionally, specify custom colors
  ) +
  scale_x_discrete(breaks =c(0,1,2,3), labels = c(1,2,3,4)) +
  scale_y_continuous(limits=c(min(data$lower_ci_rt), max(data$upper_ci_rt)),
                      labels = function(x) sprintf("%.1f", x) %>% stringr::str_replace("\\.", ",")
                      ) +
  theme_apa() +
  facet_wrap(~condition, scales = "free_y")
}
generate_comparison_plot_rt(combined_summary_individual_complete)

generate_comparison_plot_acc <-function(data, individual) {
  if (individual == TRUE) {
    shape = rep(c(rep(19,8), rep(17,4)),2)
  } else  {
    shape = rep(19,24)
  }
  sequence <- round(seq(min(c(data$lower_ci_acc, data$median_accuracy), na.rm = T)-0.1, max(c(data$lower_ci_acc, data$median_accuracy), na.rm = T)+0.09, by = 0.01),2)
  sequence <- sequence[floor(sequence * 100) %% 10 == 0]
  labels_in_percent <- sprintf("%d%%", sequence * 100)
  
  
ggplot(data = data, aes(x = factor(difficulty), y = median_accuracy, color = Berechnung)) +
  geom_point(size = 3, position = position_dodge(width = 0.6), shape = shape) +
    geom_errorbar(
    stat='identity',
    aes(
      ymin= lower_ci_acc,
      ymax = upper_ci_acc),
    width = 0.2, position = position_dodge(width = 0.6)
  ) +
  geom_line(aes(group = Berechnung), position = position_dodge(width = 0.6), linewidth = .5) +
  labs(x = "Schwierigkeit", y = "Genauigkeit") +
  ggtitle("simulierte und echte Genauigkeit in %") +
  scale_color_manual(
    labels = c('emp. Genauigkeit', 'dynamisches DDM', 'statisches DDM'),  # Optionally, specify custom labels
    breaks = c('Real Data', 'BayesFlow', 'STAN'),  # TODO check whether they are in correct order
    values = c('Real Data' = 'grey', 'BayesFlow' = 'red', 'STAN' = 'steelblue')  # Optionally, specify custom colors
  ) +
  scale_x_discrete(breaks =c(0,1,2,3), labels = c(1,2,3,4)) +
  scale_y_continuous(limits=c(min(c(data$lower_ci_acc, data$median_accuracy)),max(c(data$lower_ci_acc, data$median_accuracy))), breaks = sequence, labels = labels_in_percent) +
  theme_apa() +
  facet_wrap(~condition, scales = "free_y")
}

generate_comparison_plot_acc(combined_summary_individual_complete, individual = TRUE)
#generate_comparison_plot_rt(combined_summary_all, median_response_time)


```
load stationary models.
```{r load all stationary models}
#takes a long time to load
filenames <- list.files("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/STAN", pattern="*.rds", full.names=TRUE)
ldf <- lapply(filenames, read_rds)
# 
# filenames_shortened <-str_sub(filenames, start = -18, end = -5)
# filenames_shortened <- gsub("^(?!s)", "s", filenames_shortened, perl = T)
```


Create 1 graph for parameter comparison and 1 for rt comparison, both for 14 people individually and rt comparison also for all
```{r data resimulation for rt comparison}
set.seed(123)
person=1 #person
resimulation=1 #1 of 100 resimulations 
trial=1 #1 of 768 trials

#ldf is weirdly sorted ( 1,10,11, and so on) so we create "position" which finds the correct position in ldf to chose for person. 1-14 in ldf_id are the complex models and 15-28 the simpler ones, we only want these because there were no big differences in the loo_comparison in the STAN Workflow. So we search for the POSITIONS of 15-28 in ldf_id and store them in position.

ldf_id <- c(15, 1, 
            24, 10, 
            25, 11, 
            26, 12, 
            27, 13, 
            28, 14, 
            16, 2, 
            17, 3, 
            18, 4, 
            19, 5, 
            20, 6, 
            21, 7, 
            22, 8, 
            23, 9)
position <- match(15:28, ldf_id) # Use the match function to find positions

simulation_complete_all_14people <-  tibble() #stores all the simulated data for the stationary and the dynamic model.

for (person in 1:14) { #unique(df$id)
  #we filter for person, store some of their data and create empty tibbles.
  df_temp <- df %>% filter(id==person, 
                           tutorial==0)
  difficulty <- df_temp$difficulty 
  condition <- df_temp$speed_condition
  #condition2 <- ifelse(df_temp$speed_condition==1, 4,0) only needed if we use the more complicated model.
  simulation_complete_static <-  tibble(response_time_fake = double(), correct_fake = integer(), trial = integer(), difficulty = integer(), condition = integer()) #empty tibbles for static  Simulation
  simulation_complete_dynamic <-  tibble(response_time_fake = double(), correct_fake = integer(), trial = integer(), difficulty = integer(), condition = integer()) #empty tibbles for bayesflow simulation
  
  #we get the parameters we  want from the stationary models, the dynamic model is already loaded.
  #Here we need to use position because we choose from ldf
  posterior_samples_static <- rstan::extract(ldf[[position[person]]], pars = c("v[1]", "v[2]", "v[3]", "v[4]", "a[1]", "a[2]", "ndt")) # TO CHANGE IF INTERACTION MODEL IS USED: ,"v[5]","v[6]","v[7]","v[8]", 
  
  parameters_to_sample <- c("v[1]", "v[2]", "v[3]", "v[4]", "a[1]", "a[2]", "ndt")
  
  #This df stores the mean values and sd values for all v[1:4], a[1,2] and ndt for the static model.
  posterior_summary_static <- data.frame(
    position = 1:length(posterior_samples_static),
    mean = sapply(posterior_samples_static, mean),
    sd  = sapply(posterior_samples_static, sd),
    row.names = parameters_to_sample
  )
  
  
  #This is the df that is given to generate_parameter_plot.
  #It consists of Means and sds for the static and dynamic models for each timestep for the dynamic model
  #and of the calculated means/sds in posterior_summary_static that are identical for each trial with the same difficulty/condition
  #for posterior we can use person and not position because it is already sorted.
  
  data <- data.frame(
    dimension = 1:768,
    
    #v
    mean_v_dynamic = rowMeans(posterior_samples_dynamic[person, , , 1]),
    sd_v_dynamic = apply(posterior_samples_dynamic[person, , , 1], 1, sd),
    mean_v_static = posterior_summary_static$mean[difficulty+1], # + condition2 IF INTERACTION MODEL
    sd_v_static = posterior_summary_static$sd[difficulty+1],# + condition2 IF INTERACTION MODEL
    
    #a
    mean_a_dynamic = rowMeans(posterior_samples_dynamic[person, , , 2]),
    sd_a_dynamic = apply(posterior_samples_dynamic[person, , , 2], 1, sd),
    mean_a_static = posterior_summary_static$mean[5 + condition], #9 IF INTERACTION MODEL
    sd_a_static = posterior_summary_static$sd[5 + condition], #9 IF INTERACTION MODEL
    
    #ndt
    mean_ndt_dynamic = rowMeans(posterior_samples_dynamic[person, , , 3]),
    sd_ndt_dynamic = apply(posterior_samples_dynamic[person, , , 3], 1, sd),
    mean_ndt_static = posterior_summary_static$mean[7], #11 IF INTERACTION MODEL
    sd_ndt_static = posterior_summary_static$sd[7] # 11 IF INTERACTION MODEL
    
  )
  #create plot and save it
  generate_parameter_plot(data, condition, difficulty)
  ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/parameter_comparison/parametercomparison_subj_", person,"_M1.svg") ,  width = 7500, height = 5000, units = "px", dpi = 600)
  ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/parameter_comparison/parametercomparison_subj_", person,"_M1.png") ,  width = 7500, height = 5000, units = "px", dpi = 600)
  
  #NEW PLOT: true rt vs predicted rts
  #In this plot we want to compare real data rt with simulated data rt from the 2 models. We want to calculate:
  #100(resimulation)*768(trial)*14(person)*2(static,dynamic) rts that are summarized as median and MAD
  
  #for rt comparison plot we only want a sample of 100 of all the posterior samples
  posterior_samples_dynamic_short <- posterior_samples_dynamic[, , sample(1:4000, 100, replace=F), ] #trim array to 100 of 4000 estimations
  posterior_samples_static_short <- lapply(parameters_to_sample, function(param) {
    sample(posterior_samples_static[[param]], 100, replace = FALSE) #trim the other one as well
  })
  
  for (resimulation in 1:length(posterior_samples_dynamic_short[1,1,,1])) { 
    
    # set of resimulations.  with hardcoded v1-4 and a1-2. which of these v and a still needs to be decided for every trial
    
    rt_sim_static <- c()
    correct_sim_static <-  c()
    rt_sim_dynamic <- c()
    correct_sim_dynamic <-  c()
    
    #tibble(response_time_fake = double(), correct_fake = integer(), trial = integer(), difficulty = integer(), condition = integer())
    for (trial in 1:768) { # for every trial the posterior samples of the dynamic and the static model are loaded and a rt and correct(Y/N) are calculated and stored
      v <- posterior_samples_static_short[[1 + difficulty[trial]]] [resimulation] # + condition2[trial] IF INTERACTION STAN #difficulty[trial]  and condition2[trial] is for choosing which v is to use. [j] is for which of the 100 values of that v to use.
      a <- posterior_samples_static_short[[5 + condition[trial]]] [resimulation] # 9 IF INTERACTION STAN
      ndt <- posterior_samples_static_short[[7]] [resimulation] # 11 IF INTERACTION STAN
      output <- wiener_process(v = v, a = a, ndt = ndt) #function creates rt and correct y/n for the static model
      rt_sim_static <- c(rt_sim_static, output[1]) 
      correct_sim_static <- c(correct_sim_static, output[2])
      
      v <- posterior_samples_dynamic_short[person,trial,resimulation,1] #dims are [14,768,100,3]
      a <- posterior_samples_dynamic_short[person,trial,resimulation,2]
      ndt <- posterior_samples_dynamic_short[person,trial,resimulation,3]
      output <- wiener_process(v = v, a = a, ndt = ndt) #function creates rt and correct y/n for dynamic model
      rt_sim_dynamic <- c(rt_sim_dynamic, output[1])
      correct_sim_dynamic <- c(correct_sim_dynamic, output[2])
    }
    
    temp_simulation_static <- # put all 768 simulations in a df for 1 resimulation 
      tibble(
        response_time_fake = rt_sim_static,
        correct_fake = correct_sim_static,
        trial = 1:length(rt_sim_static),
        difficulty = difficulty,
        condition = condition,
        resimulation = resimulation)
    
    temp_simulation_dynamic <-
      tibble(
        response_time_fake = rt_sim_dynamic,
        correct_fake = correct_sim_dynamic,
        trial = 1:length(rt_sim_dynamic),
        difficulty = difficulty,
        condition = condition,
        resimulation = resimulation)
    
    #         tibble(
    #           response_time_fake = rt_sim_bf,
    #           correct_fake = correct_sim_bf,
    #           trial = 1:length(rt_sim_bf),
    #           difficulty = difficulty,
    #           condition = condition
    #         )
    simulation_complete_static <- #combine dfs for resimulations in one df for all simulations
      bind_rows(simulation_complete_static, temp_simulation_static)
    rm(temp_simulation_static) #rm temp_dfs
    simulation_complete_dynamic <-
      bind_rows(simulation_complete_dynamic, temp_simulation_dynamic)
    rm(temp_simulation_dynamic)      
    
  }
  
  simulation_complete_all <- bind_rows( #combine dynamic and static resimulations into 1 df and add id of person and source of model
    simulation_complete_dynamic %>%
      mutate(Berechnung = "BayesFlow"),
    simulation_complete_static %>%
      mutate(Berechnung = "STAN")
  ) %>% 
    mutate(person = person)
  
  simulation_complete_all_14people <- simulation_complete_all_14people %>% #add all resimulations of all people into 1 df
    bind_rows(simulation_complete_all)
  
  rm(simulation_complete_dynamic)
  rm(simulation_complete_static)
}

df_rt <- df %>% #real data
  filter(tutorial == 0) %>% #we don't use the tutorial
  mutate(
    Berechnung = "Real Data",
    condition = if_else(speed_condition == 0, "Genauigkeitsbedingung", "Geschwindigkeitsbedingung")
  ) %>% 
  group_by(condition, difficulty, Berechnung) %>% #for each condition*difficulty*Berechnung of real data we want a median and mad of rt
  summarize(
    median_response_time = median(rt),
    lower_ci_rt = median_response_time - stats::mad(rt),  #qt(0.975, n() - 1) * sd(rt) / sqrt(n()),
    upper_ci_rt = median_response_time + stats::mad(rt))         #qt(0.975, n() - 1) * sd(rt) / sqrt(n()

df_acc <- df %>% #real data
  filter(tutorial == 0) %>% #we don't use the tutorial
  mutate(
    Berechnung = "Real Data",
    condition = if_else(speed_condition == 0, "Genauigkeitsbedingung", "Geschwindigkeitsbedingung")
  ) %>% 
  group_by(condition, difficulty, Berechnung, id) %>% #for each condition*difficulty*Berechnung of real data we want a median and mad of rt
  summarize(
    accuracy = mean(correct)) %>% 
  group_by(condition, difficulty, Berechnung) %>% 
  summarize(
    median_accuracy =median(accuracy),
    lower_ci_acc = median_accuracy - stats::mad(accuracy),  #qt(0.975, n() - 1) * sd(rt) / sqrt(n()),
    upper_ci_acc = median_accuracy + stats::mad(accuracy) 
  )

df_complete <- df_rt %>%
  left_join(df_acc, by = c("condition", "difficulty", "Berechnung"))

combined_summary_all_rt <- simulation_complete_all_14people %>% #for each condition*difficulty*Berechnung of simulated data we want a median and mad of rt and mean of rt
  mutate(condition = if_else(condition == 0, "Genauigkeitsbedingung", "Geschwindigkeitsbedingung")
  ) %>% 
  group_by(condition, difficulty, Berechnung) %>%
  summarize(
    median_response_time = median(response_time_fake),
    lower_ci_rt = median_response_time - mad(response_time_fake), #qt(0.975, n() - 1) * sd(response_time_fake) / sqrt(n()),
    upper_ci_rt = median_response_time + mad(response_time_fake)  #qt(0.975, n() - 1) * sd(response_time_fake) / sqrt(n())
  )

combined_summary_all_acc <- simulation_complete_all_14people %>% #for each condition*difficulty*Berechnung of simulated data we want a median and mad of rt and mean of rt
  mutate(condition = if_else(condition == 0, "Genauigkeitsbedingung", "Geschwindigkeitsbedingung")
  ) %>% 
  group_by(condition, difficulty, Berechnung, person, resimulation) %>%
  summarize(
    accuracy = mean(correct_fake)) %>% 
  group_by(condition, difficulty, Berechnung) %>% 
  summarize(
    median_accuracy =median(accuracy),
    lower_ci_acc = median_accuracy - stats::mad(accuracy),  #qt(0.975, n() - 1) * sd(rt) / sqrt(n()),
    upper_ci_acc = median_accuracy + stats::mad(accuracy)
  )


combined_summary_all_complete <- combined_summary_all_rt %>%
  left_join(combined_summary_all_acc, by = c("condition", "difficulty", "Berechnung")) %>% 
  bind_rows( #add real data to object
    .,
    df_complete)

combined_summary_all_complete$Berechnung <- factor(
  combined_summary_all_complete$Berechnung, 
  levels = c('Real Data', 'BayesFlow', 'STAN')
)

#plot for all people, rt

generate_comparison_plot_rt(combined_summary_all_complete)
ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/rt_comparison/rt_comparison_ALL_M1.png"),  width = 6500, height = 4550, units = "px", dpi = 800)
ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/rt_comparison/rt_comparison_ALL_M1.svg"),  width = 6500, height = 4550, units = "px", dpi = 800)

##plot for all people, acc
generate_comparison_plot_acc(combined_summary_all_complete, FALSE)

ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/acc_comparison/acc_comparison_ALL_M1.png"),  width = 6500, height = 4550, units = "px", dpi = 800)
ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/acc_comparison/acc_comparison_ALL_M1.svg"),  width = 6500, height = 4550, units = "px", dpi = 800)

#individual Plots
for (person in 1:14) {
  
  df_complete <- df %>% #real data
  filter(tutorial == 0,
         id == .env$person) %>% #we don't use the tutorial
  mutate(
    Berechnung = "Real Data",
    condition = if_else(speed_condition == 0, "Genauigkeitsbedingung", "Geschwindigkeitsbedingung")
  ) %>% 
  group_by(condition, difficulty, Berechnung) %>% #for each condition*difficulty*Berechnung of real data we want a median and mad of rt
  summarize(
    median_response_time = median(rt),
    lower_ci_rt = median_response_time - stats::mad(rt),  #qt(0.975, n() - 1) * sd(rt) / sqrt(n()),
    upper_ci_rt = median_response_time + stats::mad(rt),
    median_accuracy = mean(correct)
    )         #qt(0.975, n() - 1) * sd(rt) / sqrt(n()

  
combined_summary_individual_rt <- simulation_complete_all_14people %>% #for each condition*difficulty*Berechnung of simulated data we want a median and mad of rt and mean of rt
      filter(
      person == .env$person
    ) %>% 
  mutate(condition = if_else(condition == 0, "Genauigkeitsbedingung", "Geschwindigkeitsbedingung")
  ) %>% 
  group_by(condition, difficulty, Berechnung) %>%
  summarize(
    median_response_time = median(response_time_fake),
    lower_ci_rt = median_response_time - mad(response_time_fake), #qt(0.975, n() - 1) * sd(response_time_fake) / sqrt(n()),
    upper_ci_rt = median_response_time + mad(response_time_fake)  #qt(0.975, n() - 1) * sd(response_time_fake) / sqrt(n())
  )

combined_summary_individual_acc <- simulation_complete_all_14people %>% #for each condition*difficulty*Berechnung of simulated data we want a median and mad of rt and mean of rt
      filter(
      person == .env$person
    ) %>% 
  mutate(condition = if_else(condition == 0, "Genauigkeitsbedingung", "Geschwindigkeitsbedingung")
  ) %>% 
  group_by(condition, difficulty, Berechnung, person, resimulation) %>%
  summarize(
    accuracy = mean(correct_fake)) %>% 
  group_by(condition, difficulty, Berechnung) %>% 
  summarize(
    median_accuracy =median(accuracy),
    lower_ci_acc = median_accuracy - stats::mad(accuracy),  #qt(0.975, n() - 1) * sd(rt) / sqrt(n()),
    upper_ci_acc = median_accuracy + stats::mad(accuracy)
  )


combined_summary_individual_complete <- combined_summary_individual_rt %>%
  left_join(combined_summary_individual_acc, by = c("condition", "difficulty", "Berechnung")) %>% 
  bind_rows( #add real data to object
    .,
    df_complete)

combined_summary_individual_complete$Berechnung <- factor(
  combined_summary_individual_complete$Berechnung, 
  levels = c('Real Data', 'BayesFlow', 'STAN')
)

  
  
  
  #individual plot, rt
generate_comparison_plot_rt(combined_summary_individual_complete)
  ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/rt_comparison/rt_comparison_subj_", person, "_MAD_M1.png"),  width = 6500, height = 4550, units = "px", dpi = 800)
  ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/rt_comparison/rt_comparison_subj_", person, "_MAD_M1.svg"),  width = 6500, height = 4550, units = "px", dpi = 800)
  
  #individual plot, acc
generate_comparison_plot_acc(combined_summary_individual_complete, TRUE)
  ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/acc_comparison/acc_comparison_subj_", person, "_M1.png"),  width = 6500, height = 4550, units = "px", dpi = 800)
  ggsave(paste0("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/acc_comparison/acc_comparison_subj_", person, "_M1.svg"),  width = 6500, height = 4550, units = "px", dpi = 800)
}

```




```{r remove outliers for regressions etc, eval = FALSE}
#for the manipulation check of accuracy we will calculate a bayesian logistic regression of the accuracy with difficulty and condition as predictors. 

df2 <- data.frame()
df2 <- df %>% select(all_of(colnames(df))) %>%
  filter( correct == 2)

for (i in 1:14) { #unique(df$id)
  df_temp <- df %>% 
    filter(id==i,
           tutorial==0)
    
  border <- boxplot.stats(log(df_temp$rt))$stats[1]
  df_temp <- df_temp %>% filter(log(df_temp$rt) > border)
  df2 <- df2 %>% add_row(df_temp)
}
  
df2 <- df2 %>%
  mutate(rt_in_ms = rt*1000)
```


```{r Manipulation check - logistic regression - accuracy, eval = FALSE}
bm_acc<- brm(formula = correct ~ difficulty*speed_condition + (1|id), 
                     data=df, 
                     family = bernoulli(link = "logit"),
                     warmup = 2000, 
                     iter = 4000, 
                     chains = 4, 
                     cores=parallel::detectCores(),
                     seed = 12345)
saveRDS(bm_acc, "bm_acc.rds")
bm_acc <- readRDS("~/Universität/Master Psychologie/SS 2022/Masterarbeit/bm_acc.rds")

EMM_acc <- emmeans(bm_acc, ~speed_condition*difficulty, at = list(difficulty = c(0,1,2,3)), type = "response")
EMM_acc_plot <-  emmip(EMM_acc, speed_condition ~ difficulty | speed_condition, plotit = F)
EMM_acc_plot <-  EMM_acc_plot %>% 
  mutate(
    speed_condition = rep(c("Genauigkeitsbedingung", "Geschwindigkeitsbedingung"), 4),
    xvar = difficulty + 1
    )
manip_check_1 <- emmip_ggplot(EMM_acc_plot,xlab = "Schwierigkeit", ylab = "Genauigkeit") +
  theme_apa()#, facetlab = label_value(as.data.frame(c("test", "test2")))) #,facetlab = c(0,1))
#emmeans logistic regression brms, predictor ordinal
# odds ratios aus brms Objekt bekommen
# odds_ratios <- exp(posterior_samples)
```

```{r Manipulation check -  regression - rt, eval = FALSE}
bm_rt <- brm(formula = rt_in_ms ~ difficulty*speed_condition + (1|id), 
                     data=df2, 
                     family = exgaussian(link = "identity", link_sigma = "log", link_beta = "log"),
                     warmup = 2000, 
                     iter = 4000, 
                     chains = 2, 
                     init= "0", 
                     cores=parallel::detectCores(),
                     seed = 12345)
#linear, oder difficulty raus nehmen, oder random slopes raus nehmen, nur random intercepts, Leute sind unterschiedlich gut/schnell, aber Manipulation gleich auf alle, doppelstrich > independent, dann correlations raus, 2, random intercept, nicht random slopes und 3. difficulty komplett raus nehmen. >> fixed effects, nur random intercept. 
saveRDS(bm_rt, "bm_rt.rds")
bm_rt <- readRDS("~/Universität/Master Psychologie/SS 2022/Masterarbeit/bm_rt.rds")
EMM_rt <- emmeans(bm_rt, ~speed_condition*difficulty, at = list(difficulty = c(0,1,2,3)), type = "response")
EMM_rt_plot <-  emmip(EMM_rt, speed_condition ~ difficulty | speed_condition, plotit = F)
EMM_rt_plot <-  EMM_rt_plot %>% 
  mutate(
    speed_condition = rep(c("Genauigkeitsbedingung", "Geschwindigkeitsbedingung"), 4),
    xvar = difficulty + 1)#,
    # yvar = yvar,
    # LCL = LCL,
    # UCL = UCL
    # )
manip_check_2 <-  emmip_ggplot(EMM_rt_plot,xlab = "Schwierigkeit", ylab = "Reaktionszeit") +
  theme_apa()
manip_check_2
manip_check_total <- manip_check_1 / manip_check_2
manip_check_total
setwd("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder")
ggsave("C:/Users/steff/Documents/Universität/Master Psychologie/SS 2022/Masterarbeit/Bilder/plots/manipulation_check_plot.png", manip_check_total, width = 5000, height = 3500, units = "px", dpi = 800)
```


```{r}
df_all <- read_csv("Universität/Master Psychologie/SS 2022/Masterarbeit/Experiment/Daten/Daten_cleaned/df_all.csv")

kable(df_all %>% 
  filter(tutorial == 0) %>% 
  group_by(code, blauetaste, erstebedingung) %>% 
  slice(1) %>% 
  ungroup() %>% 
  arrange(...1) %>% 
  select(code, blauetaste, erstebedingung)%>% 
  mutate(code = seq(1, n()),
         erstebedingung = ifelse(erstebedingung == "speed", "Geschwindigkeitsbedingung", "Genauigkeitsbedingung")
         ))
```

```{r}


for (person in 1:14) {
  
  df_temp <-  df %>% filter(
    tutorial == 0,
    id == person
  )
  # Assuming df is your dataframe and difficulty is the column of interest
  runs <- rle(df_temp$difficulty)
  
  # Create a new dataframe with lengths and values
  result <- data.frame(lengths = runs$lengths, values = runs$values)
  
  # Filter the dataframe based on your conditions
  result <- result[result$values %in% 0:3 & result$lengths %in% 0:32,]
  
  # Count the occurrences
  print(table(result))
}


```

